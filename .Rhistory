colsNA     <- which(percentNA > 0.97)
data       <- data      [, -colsNA]
validation <- validation[, -colsNA]
percentNA  <- as.vector(colMeans(is.na(data)))
colsNA     <- which(percentNA > 0.97)
data       <- data      [, -colsNA]
validation <- validation[, -colsNA]
nsv        <- nearZeroVar(data)
data       <- data      [, -nsv]
validation <- validation[, -nsv]
inTrain    <- createDataPartition(data$classe, p=0.80, list=F)
training   <- data[ inTrain,]
testing    <- data[-inTrain,]
dim(training)
dim(testing)
3923/15699
3923/(3923+15699)
modFit1<- train(classe ~ ., method= "rf" , data= training, verbose= F)
library(doMC)
install.packages("doMC")
library(parallel)
library(parallel)
modFit1<- train(classe ~ ., method= "rf" , data= training, verbose= F)
library(doParallel)
install.packages("doParallel")
library(doParallel)
modFit1<- train(classe ~ ., method= "rf" , data= training, verbose= F)
library(caret)
data       <- read.csv("pml-training.csv") # training + testing data
validation <- read.csv("pml-testing.csv" ) # validatation       data
# remove index column (not a predictor)
data$X       <- NULL
validation$X <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(data)))
colsNA     <- which(percentNA > 0.97)
data       <- data      [, -colsNA]
validation <- validation[, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(data)
data       <- data      [, -nsv]
validation <- validation[, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(data, is.factor)))
#cors       <- abs(cor(data[,-colsFactor]))
#diag(cors) <- 0
# sapply(1:58, function(x) skewness(data[, x]))
set.seed(123) # ensure reproducability
inTrain    <- createDataPartition(data$classe, p= 0.80, list= F)
training   <- data[ inTrain,]
testing    <- data[-inTrain,]
fitControl <- trainControl(method= "repeatedcv", number= 10, repeats= 10) # 10-fold cross-validation
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
fitControl <- trainControl(method= "cv", number= 10, repeats= 10) # 10-fold cross-validation
fitControl <- trainControl(method= "cv", number= 10, repeats= 10) # 10-fold cross-validation
fitControl <- trainControl(method= "cv", number= 10, repeats= 1) # 10-fold cross-validation
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
modFit1    <- train(classe ~ ., method= "svm" , data= training, trControl= fitControl)
names(getModelInfo())
modFit1    <- train(classe ~ ., method= "nb" , data= training, trControl= fitControl)
fitControl <- trainControl(method= "cv", number= 10, repeats= 1) # 10-fold cross-validation
modFit1    <- train(classe ~ ., preProcess= "pca", method= "rf" , data= training, trControl= fitControl)
modFit1    <- train(classe ~ ., preProcess= "pca", method= "nb" , data= training, trControl= fitControl)
warnings()
modFit1    <- train(classe ~ ., method= "nb" , data= training, trControl= fitControl)
modFit1    <- train(classe ~ ., method= "rpart" , data= training, trControl= fitControl)
modFit1
modFit1$finalModel
predict(modFit, newdata= training)
predict(modFit1, newdata= training)
pred <- predict(modFit1, newdata= training)
pred1 <- predict(modFit1, newdata= testing)
confusionMatrix(pred1, testing$Classe)$overall[1]
confusionMatrix(pred1, testing$classe)$overall[1]
modFit1    <- train(classe ~ ., method= "lm" , data= training, trControl= fitControl)
modFit1    <- train(classe ~ ., method= "glm" , data= training, trControl= fitControl)
modFit1    <- train(classe ~ ., method= "gbm" , data= training, trControl= fitControl)
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T) # 10-fold cross-validation
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
preProc <- preProcess(train[,-58], method="pca", thresh=0.99)
preProc <- preProcess(training[,-58], method="pca", thresh=0.99)
preProc <- preProcess(training[,-colsFactor], method="pca", thresh=0.99)
preProc
preProcess(training[,-colsFactor], method="pca", thresh=0.99)
preProcess(training[,-colsFactor], method="pca", thresh=0.9)
preProcess(training[,-colsFactor], method="pca", thresh=0.999)
preProcess(training[,-colsFactor], method="pca", thresh=0.99)
preProc
modFit1    <- train(classe ~ ., method= "rf" , data= training, preProcess= prePoc, trControl= fitControl)
modFit1    <- train(classe ~ ., method= "rf" , data= training, preProcess= preProc, trControl= fitControl)
predict(preProc, training[,-colsFactor])
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh= 0.99)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh1= 0.99)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh= 1.99)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh= 0.99)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh= 0.1)
preProcess(training[,-colsFactor], method="pca", thresh=0.99)
preProcess(training[,-colsFactor], method="pca", thresh=0.01)
preProcess(training[,-colsFactor], method="pca", thresh=0.9)
preProcess(training[,-colsFactor], method="pca", thresh=0.01)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca", thresh= 0.01)
preProc <- preProcess(training[,-colsFactor], method="pca", thresh=0.9)
preProc <- preProcess(training[,-colsFactor], method="pca", thresh=0.99)
preProc
inTrain    <- createDataPartition(data$classe, p= 0.80, list= F)
training   <- data[ inTrain,]
testing    <- data[-inTrain,]
set.seed(123) # ensure reproducability
inTrain    <- createDataPartition(data$classe, p= 0.80, list= F)
training   <- data[ inTrain,]
testing    <- data[-inTrain,]
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
library(caret)
data       <- read.csv("pml-training.csv") # training + test data
validation <- read.csv("pml-testing.csv" ) # validatation    data
# remove index column (not a predictor)
data$X       <- NULL
validation$X <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(data)))
colsNA     <- which(percentNA > 0.97)
data       <- data      [, -colsNA]
validation <- validation[, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(data)
data       <- data      [, -nsv]
validation <- validation[, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(data, is.factor)))
#cors       <- abs(cor(data[,-colsFactor]))
#diag(cors) <- 0
# sapply(1:58, function(x) skewness(data[, x]))
set.seed(123) # ensure reproducability
inTrain    <- createDataPartition(data$classe, p= 0.80, list= F)
training   <- data[ inTrain,]
test       <- data[-inTrain,]
# reduce number of predictors using Principal Component Analysis, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
dim(predict(preProc, training[,-colsFactor]))
dim(colbind(predict(preProc, training[,-colsFactor]), training[colsFactor])
)
dim(colBind(predict(preProc, training[,-colsFactor]), training[colsFactor]))
dim(cnind(predict(preProc, training[,-colsFactor]), training[colsFactor]))
dim(cbind(predict(preProc, training[,-colsFactor]), training[colsFactor]))
training   <- cbind(predict(preProc, training[,-colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [,-colsFactor]), test    [colsFactor])
validation <- cbind(predict(preProc, validation[,-colsFactor]), validation[colsFactor])
View(validation)
View(validation)
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T) # 10-fold cross-validation
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl, preProcess="pca")
library(caret)
data       <- read.csv("pml-training.csv") # training + test data
validation <- read.csv("pml-testing.csv" ) # validatation    data
# remove index column (not a predictor)
data$X       <- NULL
validation$X <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(data)))
colsNA     <- which(percentNA > 0.97)
data       <- data      [, -colsNA]
validation <- validation[, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(data)
data       <- data      [, -nsv]
validation <- validation[, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(data, is.factor)))
#cors       <- abs(cor(data[,-colsFactor]))
#diag(cors) <- 0
# sapply(1:58, function(x) skewness(data[, x]))
set.seed(123) # ensure reproducability
inTrain    <- createDataPartition(data$classe, p= 0.80, list= F)
training   <- data[ inTrain,]
test       <- data[-inTrain,]
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
# replace training, test and validation sets with PCA results; bind removed factor columns
training   <- cbind(predict(preProc, training  [,-colsFactor]), training  [colsFactor])
test       <- cbind(predict(preProc, test      [,-colsFactor]), test      [colsFactor])
validation <- cbind(predict(preProc, validation[,-colsFactor]), validation[colsFactor])
# 10-fold cross-validation training
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
p1 <- predict(modFit1, test)
confusionMatrix(p1, test$classe)
View(validation)
View(validation)
q1 <- predict(modFit1, validation)
q1
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(q)
pml_write_files(q1)
modFit1
getTree(modFit1$finalModel, k=2)
getTree(modFit1$finalModel)
getTree(modFit1$finalModel, k=2
)
getTree(modFit1$finalModel, k=20)
getTree(modFit1$finalModel, k=20000000)
modFit1$finalModel
library(caret)
training     <- read.csv("pml-training.csv") # training data
test         <- read.csv("pml-testing.csv" ) # test     data
# remove index column (not a predictor)
training$X   <- NULL
test$X       <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(training)))
colsNA     <- which(percentNA > 0.97)
training   <- training[, -colsNA]
test       <- test    [, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(training)
training   <- training[, -nsv]
test       <- test    [, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(training, is.factor)))
# ensure reproducability
set.seed(123)
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
# replace training and test sets with PCA results; bind removed factor columns
training   <- cbind(predict(preProc, training[,-colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [,-colsFactor]), test    [colsFactor])
# 10-fold cross-validation training
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T)
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
training     <- read.csv("pml-training.csv") # training data
test         <- read.csv("pml-testing.csv" ) # test     data
# remove index column (not a predictor)
training$X   <- NULL
test$X       <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(training)))
colsNA     <- which(percentNA > 0.97)
training   <- training[, -colsNA]
test       <- test    [, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(training)
training   <- training[, -nsv]
test       <- test    [, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(training, is.factor)))
# ensure reproducability
set.seed(123)
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
preProcess(training[,-colsFactor], method= "pca", thresh= 0.98)
preProcess(training[,-colsFactor], method= "pca", thresh= 0.97)
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.97)
training   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
preProc
training   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])
library(caret)
training     <- read.csv("pml-training.csv") # training data
test         <- read.csv("pml-testing.csv" ) # test     data
# remove index column (not a predictor)
training$X   <- NULL
test$X       <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(training)))
colsNA     <- which(percentNA > 0.97)
training   <- training[, -colsNA]
test       <- test    [, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(training)
training   <- training[, -nsv]
test       <- test    [, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(training, is.factor)))
# ensure reproducability
set.seed(123)
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 97% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.97)
# replace training and test sets with PCA results; bind removed factor columns
training   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T)
modFit1    <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
modFit2    <- train(classe ~ ., method= "gbm", data= training, trControl= fitControl)
p1 <- predict(modFit1, test)
p2 <- predict(modFit2, test)
confusionMatrix(p1, test$classe)$overall[1]
confusionMatrix(p2, test$classe)$overall[1]
p1
p2
View(test)
View(test)
modFit1
confusionMatrix(predict(modFit1, data), data$classe)$overall[1]
predict(modFit1, data)
confusionMatrix(predict(modFit1, training), training$classe)$overall[1]
confusionMatrix(predict(modFit1, training), training$classe)$overall
confusionMatrix(predict(modFit1, training), training$classe)
confusionMatrix(predict(modFit2, training), training$classe)
modFit1
library(caret)
training     <- read.csv("pml-training.csv") # training data
test         <- read.csv("pml-testing.csv" ) # test     data
# remove index column (not a predictor)
training$X   <- NULL
test$X       <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(training)))
colsNA     <- which(percentNA > 0.97)
training   <- training[, -colsNA]
test       <- test    [, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(training)
training   <- training[, -nsv]
test       <- test    [, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(training, is.factor)))
# ensure reproducability
set.seed(123)
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
# replace training and test sets with PCA results; bind removed factor columns
training   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])
# 10-fold cross-validation training
fitControl <- trainControl(method= "cv", number= 10, repeats= 1, verboseIter= T)
modFit     <- train(classe ~ ., method= "rf" , data= training, trControl= fitControl)
p          <- predict(modFit, test)
confusionMatrix(p, test$classe)$overall[1]
confusionMatrix(p, test$classe)
p
test$classe
test
confusionMatrix(p, train$classe)
confusionMatrix(p, training$classe)
p          <- predict(modFit, training)
confusionMatrix(p, training$classe)
p          <- predict(modFit, test)
p
plot.enet(modFit$finalModel, xvar="penalty", use.color=T)
getTree(modFit1$finalModel, k= 2)
getTree(modFit$finalModel, k= 2)
head(getTree(modFit$finalModel, k= 2))
dim(training)
training   <- read.csv("pml-training.csv") # training data
test       <- read.csv("pml-testing.csv" ) # test     data
dim(training)
dim(training)[1]
modFit
modFit$finalModel
1
2
modFit
modFit$finalModel
modFit
modFit$Accuracy
modFit$results
modFit$results.Accuracy
modFit$results$Accuracy
max(modFit$results$Accuracy)
Accuracy*100
Accuracy <- max(modFit$results$Accuracy)
`r 1`
predict(modelFit, testing)
predict(modFit, testing)
predict(modFit, test)
modFit
modFit$mtry
postResample(modFit, training))
postResample(modFit, training)
postResample(predict(modFit, training, training$classe)
)
postResample(predict(modFit, training), training$classe)
predict(modFit, training)
predict(modFit, training$classe)
head(training)
dim(training)
training     <- read.csv("pml-training.csv") # training data
test         <- read.csv("pml-testing.csv" ) # test     data
# remove index column (not a predictor)
training$X   <- NULL
test$X       <- NULL
# remove raw timestamp columns
#data$raw_timestamp_part_1 <- NULL
#validation$raw_timestamp_part_1  <- NULL
#data$raw_timestamp_part_2 <- NULL
#validation$raw_timestamp_part_2  <- NULL
# remove predictors where more than 97% of the values are NA
percentNA  <- as.vector(colMeans(is.na(training)))
colsNA     <- which(percentNA > 0.97)
training   <- training[, -colsNA]
test       <- test    [, -colsNA]
# remove near-zero variance predictors
nsv        <- nearZeroVar(training)
training   <- training[, -nsv]
test       <- test    [, -nsv]
# find which predictors are factor predictors
colsFactor <- as.vector(which(sapply(training, is.factor)))
# ensure reproducability
set.seed(123)
# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance
preProc    <- preProcess(training[,-colsFactor], method= "pca", thresh= 0.99)
# replace training and test sets with PCA results; bind removed factor columns
training   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])
test       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])
predict(modFit, training$classe)
predict(modFit, training)
postResample(predict(modFit, training), training$classe)
confusionMatrix(p, training$classe)
confusionMatrix(p, training)
confusionMatrix(p, training$classe)
training$classe
confusionMatrix(p, training$classe)
p          <- predict(modFit, training)
confusionMatrix(p, training$classe)
library(caret)
max(modFit$results$Accuracy)
training$classe
modeFit
modelFit
modFit
modFit$Accuracy
modFit$results$Accuracy
options(digit = 5)
modFit$results$Accuracy
modFit$results$Accuracy
modFit
confusionMatrix(p, training$classe)
library(caret)
confusionMatrix(p, training$classe)
confusionMatrix(p, training$classe)$finalModel
confusionMatrix(p, training$classe)$accuracy
confusionMatrix(p, training$classe)$Aaccuracy
confusionMatrix(p, training$classe)$Accuracy
confusionMatrix(p, training$classe)$
$
attributes(confusionMatrix(p, training$classe))
confusionMatrix(p, training$classe)$overall
confusionMatrix(p, training$classe)
confusionMatrix(p, training$classe)$overall
attributes(confusionMatrix(p, training$classe)$overall)
confusionMatrix(p, training$classe)$overall$AccuracyLower
confusionMatrix(p, training$classe)$overall.AccuracyLower
confusionMatrix(p, training$classe)$overall$AccuracyLower
confusionMatrix(p, training$classe)$overall.AccuracyLower
confusionMatrix(p, training$classe)$overall$names$AccuracyLower
confusionMatrix(p, training$classe)$overall$names.AccuracyLower
confusionMatrix(p, training$classe)$overall$names
confusionMatrix(p, training$classe)$overall$AccuracyLower
confusionMatrix(p, training$classe)$overal.names
confusionMatrix(p, training$classe)$overall$names
confusionMatrix(p, training$classe)$overall.names
confusionMatrix(p, training$classe)$overall$AccuracyLower
confusionMatrix(p, training$classe)$overall.AccuracyLower
confusionMatrix(p, training$classe)$overall
confusionMatrix(p, training$classe)$overall[3]
confusionMatrix(p, training$classe)$overall[4]
modFit$results$Accuracy
which.max(modFit$results$Accuracy)
modFit$results$Accuracy[2]
modFit
attributes(modFit)
modFit$maximize
modFit$pred
modFit$modelInfo
modFit$results
attributes(modFit$results)
modFit$results$Accuracy
modFit$results
