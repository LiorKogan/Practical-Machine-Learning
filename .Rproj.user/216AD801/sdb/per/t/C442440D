{
    "contents" : "library(caret)\n\ndata       <- read.csv(\"pml-training.csv\") # training + test data\nvalidation <- read.csv(\"pml-testing.csv\" ) # validatation    data\n\n# remove index column (not a predictor)\ndata$X       <- NULL\nvalidation$X <- NULL\n\n# remove raw timestamp columns\n#data$raw_timestamp_part_1 <- NULL\n#validation$raw_timestamp_part_1  <- NULL\n#data$raw_timestamp_part_2 <- NULL\n#validation$raw_timestamp_part_2  <- NULL\n\n# remove predictors where more than 97% of the values are NA\npercentNA  <- as.vector(colMeans(is.na(data)))\ncolsNA     <- which(percentNA > 0.97)\ndata       <- data      [, -colsNA]\nvalidation <- validation[, -colsNA]\n\n# remove near-zero variance predictors \nnsv        <- nearZeroVar(data)\ndata       <- data      [, -nsv]\nvalidation <- validation[, -nsv]\n\n# find which predictors are factor predictors\ncolsFactor <- as.vector(which(sapply(data, is.factor)))\n\n#cors       <- abs(cor(data[,-colsFactor]))\n#diag(cors) <- 0\n\n# sapply(1:58, function(x) skewness(data[, x]))\n\nset.seed(123) # ensure reproducability\n\ninTrain    <- createDataPartition(data$classe, p= 0.80, list= F)\ntraining   <- data[ inTrain,]\ntest       <- data[-inTrain,]\n\n# further reduce the number of predictors using Principal Component Analysis on training data, retaining 99% of the variance\npreProc    <- preProcess(training[,-colsFactor], method= \"pca\", thresh= 0.99)\n\n# replace training, test and validation sets with PCA results; bind removed factor columns\ntraining   <- cbind(predict(preProc, training  [,-colsFactor]), training  [colsFactor])\ntest       <- cbind(predict(preProc, test      [,-colsFactor]), test      [colsFactor])\nvalidation <- cbind(predict(preProc, validation[,-colsFactor]), validation[colsFactor])\n\n# 10-fold cross-validation training\nfitControl <- trainControl(method= \"cv\", number= 10, repeats= 1, verboseIter= T)\n\n\nmodFit1    <- train(classe ~ ., method= \"rf\" , data= training, trControl= fitControl)\nmodFit2    <- train(classe ~ ., method= \"gbm\", data= training, trControl= fitControl)\n\np1 <- predict(modFit1, test)\np2 <- predict(modFit2, test)\n\nconfusionMatrix(p1, test$classe)$overall[1]\nconfusionMatrix(p2, test$classe)$overall[1]\n\nq1 <- predict(modFit1, validation)\nq2 <- predict(modFit2, validation)\n\nconfusionMatrix(q1, validation$classe)$overall[1]\nconfusionMatrix(q2, validation$classe)$overall[1]\n\n# get structure of the randomForest tree k\n# getTree(modFit1$finalModel, k= 2)\n",
    "created" : 1405760766890.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "936427804",
    "id" : "C442440D",
    "lastKnownWriteTime" : 1405789277,
    "path" : "C:/My GitHub/Practical_Machine_Learning_Prj/1.R",
    "project_path" : "1.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}