{
    "contents" : "## A Predictive Model for the Weight Lifting Exercises Dataset\n\n### Synopsis\n\nIn this project, we construct a predictive classification model based on the Weight Lifting Exercises dataset.\n\nThe training data used for this project is available at https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv, and the test data is available at https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv. Information about this data can be find at http://groupware.les.inf.puc-rio.br/har.\n\nThe model classifies how a weight lifting exercise was executed: Exactly according to the specification (class A), or with with a common mistake type (classes B-E).\n\n### Reading the data\n\n```{r}\nlibrary(caret)\nset.seed(123)\n\ntraining   <- read.csv(\"pml-training.csv\") # training data\ntest       <- read.csv(\"pml-testing.csv\" ) # test     data\n```\n\nThe training data contains `r dim(training)[1]` cases, and `r dim(training)[2]` variables (`r dim(training)[2]-1` predictors, and the true class). The test data contains `r dim(test)[1]` cases.\n\n### Selecting and preprocessing predictors\n\nFirst we will remove the index column (which is not a predictor)\n\n```{r}\ntraining$X <- NULL\ntest$X     <- NULL\n```\n\nNext, we will remove predictors where more than 97% of the values are NA:\n\n```{r}\npercentNA  <- as.vector(colMeans(is.na(training)))\ncolsNA     <- which(percentNA > 0.97)\ntraining   <- training[, -colsNA]\ntest       <- test    [, -colsNA]\n```\n\nWe're now left with `r dim(training)[2]-1` predictors.   \n\nNext, we'll remove all near-zero variance predictors:\n\n```{r}\nnsv        <- nearZeroVar(training)\ntraining   <- training[, -nsv]\ntest       <- test    [, -nsv]\n```\n\nWe're now left with `r dim(training)[2]-1` predictors.\n\nWe will further reduce the number of predictors using Principal Component Analysis on all non-factor predictors, retaining 99% of the variance:\n\n```{r}\ncolsFactor <- as.vector(which(sapply(training, is.factor)))\npreProc    <- preProcess(training[,-colsFactor], method= \"pca\", thresh= 0.99)\n\ntraining   <- cbind(predict(preProc, training[, -colsFactor]), training[colsFactor])\ntest       <- cbind(predict(preProc, test    [, -colsFactor]), test    [colsFactor])\n```\n\nWe're now left with `r dim(training)[2]-1` predictors.\n\n### Building the model\n\nWe'll train a random forest model using 10-fold cross validation - on all the training data:\n\n```{r}\nfitControl <- trainControl(method= \"cv\", number= 10, repeats= 1, verboseIter= F)\nmodFit     <- train(classe ~ ., method= \"rf\" , data= training, trControl= fitControl)\n```\n\n### Evaluating the model\n\n```{r}\nmodFit\nAccuracy   <- max(modFit$results$Accuracy)\n```\n\nBased on the 10-folds cross validation results, the estimated accuracy of the model is `r Accuracy*100`%. \nHence, the out-of-sample error is `r (1-Accuracy)*100`%\n\nThis Accuracy is the average accuracy for the 10 cross-validation folds:\n\n```{r}\nmodFit$resample\nmean(modFit$resample$Accuracy)\n```\n\n\nRunning the model on the train set produce the following results:\n\n```{r}\np          <- predict(modFit, training)\nconfusionMatrix(p, training$classe)\n```\n\n### Prediction for the test set\n\n```{r}\npredict(modFit, test)\n```\n",
    "created" : 1405874315027.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1771277845",
    "id" : "F88DEBF3",
    "lastKnownWriteTime" : 1406321917,
    "path" : "C:/My GitHub/Practical-Machine-Learning/WLE.Rmd",
    "project_path" : "WLE.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}